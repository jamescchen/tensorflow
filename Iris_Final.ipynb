{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#6/28/17\n",
    "#**placeholder part of the data**\n",
    "#read in the inputs in the correct format, x and y\n",
    "\n",
    "\n",
    "#**session run part of the data**\n",
    "#trending loss, text loss (check to see if it’s underfitting or overfitting?)\n",
    "\n",
    "#if it’s underfitting, add more features\n",
    "#if it’s overfitting, give it more data (for regulation)\n",
    "\n",
    "#HOW TO IMPORT IRIS DATA SET\n",
    "#block 1:\n",
    "#from sklearn import datasets\n",
    "#import pandas as pd\n",
    "\n",
    "#block 2:\n",
    "#iris = datasets.load_iris()\n",
    "\n",
    "#call “iris”, returns entire data set\n",
    "\n",
    "#“iris.feature_names”\n",
    "#“iris.data\"\n",
    "\n",
    "#call “iris.target_names”\n",
    "#“iris.target”\n",
    "\n",
    "#give it the data, tells you what species of flower it is; array of flower species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "rng = numpy.random\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# parameters\n",
    "learning_rate = 0.01\n",
    "training_epochs = 1000\n",
    "display_step = 50\n",
    "\n",
    "# Network Parameters\n",
    "# n_hidden_1 = 256 # 1st layer number of features\n",
    "# n_hidden_2 = 256 # 2nd layer number of features\n",
    "\n",
    "n_features = 4 # number of characteristics\n",
    "n_classes = 3 # number of flower species\n",
    "\n",
    "# tf Graph input\n",
    "x = tf.placeholder(\"float\", [None, n_features])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "\n",
    "# number of rows\n",
    "# n_samples = x.shape([0])\n",
    "\n",
    "\n",
    "# Set model weights and bias\n",
    "W = tf.Variable(tf.random_normal([n_features, n_classes]))\n",
    "b = tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "\n",
    "# Construct a linear model\n",
    "hyp = tf.add(tf.matmul(x, W), b)\n",
    "\n",
    "# Mean squared error\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(hyp), reduction_indices=[1]))\n",
    "\n",
    "# Gradient descent\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# Launch the graph\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    \n",
    "    \n",
    "# use numpy to separate into training and test set\n",
    "    \n",
    "    \n",
    "# softmax\n",
    "# soft = tf.nn.softmax_cross_entropy_with_logits(logits=pred)\n",
    "\n",
    "#one hot\n",
    "# one = tf.one_hot(indices=soft, on_value=1, off_value=0, axis=-1)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
